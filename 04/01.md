# 쿠버네티스 리소스

`Pod` 리소스를 기초로 더 많은 기능들을 내포하고 있는 리소스들을 알아보도록 하겠습니다.

## ReplicaSet

`ReplicaSet`은 이름에서도 알 수 있듯이 `Pod`를 복제(replicate)해 줍니다.
```bash
cat << EOF | kubectl apply -f -
apiVersion: apps/v1
kind: ReplicaSet
metadata:
  name: mynginx-rs
  labels:
    app: mynginx-rs
spec:
  replicas: 1
  selector:
    matchLabels:
      app: mynginx-rs
  template:
    metadata:
      labels:
        app: mynginx-rs
    spec:
      containers:
      - name: nginx
        image: nginx
EOF
```

- `replicas`: 복제할 `Pod`의 개수를 정의합니다. `ReplicaSet`에서 해당 `Pod` 개수를 유지 시켜 줍니다.
- `selector.matchLabels`: `Service`와 마찬가지로 라벨을 통하여 유지시켜야할 `Pod`를 찾습니다. 예시에서는 app: mygninx-rs 라는 라벨을 가진 `Pod`의 개수를 2로 유지한다는 것을 의미합니다.
- `template`: 유지시켜야할 `Pod`를 정의합니다. 지금까지 배운 `Pod`의 spec과 동일합니다.

```bash
kubectl get pod
# NAME              READY   STATUS      RESTARTS   AGE
# mynginx-rs-jc496  1/1     Running     0          6s
```

기존의 `Pod`와는 조금 다르게 뒤에 랜덤 문자열이 붙은 것을 확인할 수 있습니다. `mynginx-rs-XXXX` 그 이유는 해당 `Pod`를 `ReplicaSet`이 만들었기 때문입니다.

```bash
kubectl get replicaset  # 축약시, rs
# NAME          DESIRED   CURRENT   READY   AGE
# mynginx-rs    1         1         1       1m

```

- DESIRED: 유지시켜야할 `Pod`의 개수를 의미합니다.
- CURRENT: 현재 `Pod`의 개수를 의미합니다.
- READY: 현재 생성된 `Pod` 중 정상 동작하고 있는 (livenessProbe) 개수를 의미합니다.

`Pod`의 개수를 2개로 늘려 보겠습니다.

```bash
kubectl scale rs --replicas 2 mynginx-rs

kubectl get rs
# NAME          DESIRED   CURRENT   READY   AGE
# mynginx-rs    2         2         2       1m

kubectl get pod
# NAME              READY   STATUS      RESTARTS   AGE
# mynginx-rs-jc496  1/1     Running     0          2m
# mynginx-rs-dc20x  1/1     Running     0          9s
```

`Pod`를 강제로 삭제하면 어떻게 될까요?

```bash
kubectl delete pod mynginx-rs-jc496
# pod "mynginx-rs-jc496" deleted

kubectl get pod
# NAME              READY   STATUS      RESTARTS   AGE
# mynginx-rs-dc20x  1/1     Running     0          1m
# mynginx-rs-d8kvl  1/1     Running     0          3s
```

`Pod`를 삭제해도 새로운 `Pod`가 `ReplicaSet`에 의해서 생성되는 것을 확인할 수 있습니다.

이처럼 일정 수의 컨테이너를 지속적으로 유지시켜야 하는 경우, (web server 등) `ReplicaSet` 리소스를 이용하면 편리하게 운영할 수 있습니다.

`ReplicaSet` 자체를 삭제해 봅시다.

```bash
kubectl delete rs mynginx-rs
#replicaset.apps "mynginx-rs" deleted

kubectl get rs

kubectl get pod
```

## Deployment

`Deployment` 리소스는 `ReplicaSet` 리소스와 거의 유사하지만 몇가지 기능이 더 있습니다. 리소스의 이름처럼 배포에 특화된 기능이 있습니다. 변경점이 발생하여 새로운 `Pod`를 생성때 기존 `Pod` history를 전부 기억하고 있어 필요할 때마다 손쉽게 rollback을 할 수 있게 해줍니다.
먼저 `Deployment` 리소스를 생성해 보겠습니다. `Deployment`의 정의서는 `ReplicaSet`과 거의 유사하지만 배포 전략 (`strategy`)을 취할 수 있습니다.

```bash
cat << EOF | kubectl apply -f -
apiVersion: apps/v1
kind: Deployment
metadata:
  name: mynginx-deploy
  labels:
    app: nginx
spec:
  replicas: 3
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxUnavailable: 25%  
      maxSurge: 25%
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx:1.7.9
EOF
```

#### `strategy.type`
배포 전략 종류를 선택한다. `RollingUpdate`와 `Recreate`이 있습니다. `Recreate` 선택시, 새로운 `Pod`가 생성가 생성될 때 기존 `Pod`가 삭제되고 새로운 `Pod`가 생성됩니다. (기존 `Pod` 생성 전략)
`RollingUpdate` 선택시, 점진적으로 업데이트가 일어납니다. 서비스가 중단되면 안되는 웹 페이지 등에서 활용할 수 있습니다. 이때 아래 설정값에 따라 얼마나 점진적으로 업데이트가 일어날지 설정할 수 있습니다.

#### `strategy.rollingUpdate.maxUnavailable`
최대 중단 `Pod` 개수 (혹은 비율). 예를 들어 총 10개 replica에 maxUnavailable의 비율이 25%면 약 3개의 `Pod`가 RollingUpdate시에 일시 중단될 수 있다는 것을 의미합니다.

#### `strategy.rollingUpdate.maxSurge`
최대 동시 `Pod` 개수 (혹은 비율). 예를 들어 총 10개 replica에 maxSurge의 비율이 25%면 약 3개의 `Pod`가 초과하여 최대 13개까지 생성될 수 있다는 것을 의미합니다.

예시의 설정으로 RollingUpdate시, 최소 7개에서 최대 13개까지의 `Pod`가 점진적으로 업데이트 된다고 볼 수 있습니다.

```bash
kubectl get deployment  # 혹은 deploy

#####################
# 배포 변경
#####################
# 기존 nginx 버전 1.7.9에서 1.9.1로 업데이트
kubectl set image deployment mynginx-deploy nginx=nginx:1.9.1 --record
# 혹은 직접 edit
kubectl edit deployment mynginx-deploy
# 업데이트 진행 상황 확인
watch kubectl get pod
```

```bash
#####################
# 배포 상태 확인
#####################
# 업데이트 상태 확인
kubectl rollout status deployment mynginx-deploy
# Deployment 상태 확인
kubectl describe deployment mynginx-deploy
```

```bash
#####################
# 롤백
#####################
# 1.9.1 버전에서 1.9.21 버전으로 업데이트 (에러 발생)
kubectl set image deployment mynginx-deploy nginx=nginx:1.9.21 --record  # no such image version
# 업데이트 히스토리 확인
kubectl rollout history deployment mynginx-deploy
# 잘못 설정된 1.9.21에서 --> 1.9.1로 롤백
kubectl rollout undo deployment mynginx-deploy
# 배포 히스토리 버전 1로 업데이트
kubectl rollout undo deployment mynginx-deploy --to-revision=1
```

```bash
#####################
# replica 수정
#####################
# replica 개수를 5로 업데이트
kubectl scale deployment mynginx-deploy --replicas=6 --record
# 업데이트 히스토리 확인
kubectl rollout history deployment mynginx-deploy
```

```bash
kubectl delete deploy mynginx-deploy
```


## DaemonSet

`DaemonSet` 리소스는 모든 노드에 동일한 `Pod`를 실행시키고자 할 때 사용하는 리소스입니다. 리소스 모니터링, 로그 수집기 등과 같이 모든 노드에 동일한 작업을 수행할 때 자주 사용합니다. 다음은 모든 노드의 로그 정보를 추출하는 `fluentd` `DaemonSet` 예제입니다.

```yaml
# fluentd.yaml
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: fluentd
spec:
  selector:
    matchLabels:
      name: fluentd
  template:
    metadata:
      labels:
        name: fluentd
    spec:
      containers:
      - name: fluentd
        image: quay.io/fluentd_elasticsearch/fluentd:v2.5.2
        volumeMounts:
        - name: varlibdockercontainers
          mountPath: /var/lib/docker/containers
          readOnly: true
      volumes:
      - name: varlibdockercontainers
        hostPath:
          path: /var/lib/docker/containers
```

`DaemonSet`의 YAML 정의서는 간단합니다. `ReplicaSet`에서 살펴 본 것과 같이 `selector`와 `template`이 있습니다. `template`에 원하는 `Pod` 스펙을 정의하면 해당 `Pod`가 모든 노드에 일괄적으로 실행됩니다.

- `selector.matchLabels`: 라벨링 시스템을 이용하여 모든 노드에서 실행될 `Pod`를 선택합니다.
- `template`: 모든 노드에서 생성될 `Pod`를 정의합니다.

```bash
kubectl apply -f fluentd.yaml
# daemonset.apps/fluentd created

kubectl get daemonset   # 축약 시, ds
# NAME      DESIRED   CURRENT   READY   UP-TO-DATE   AVAILABLE   NODE ..
# fluentd   1         1         1       1            1                ..

kubectl get pod -owide
# NAME           READY  STATUS    RESTARTS  AGE   IP          NODE    ..
# fluentd-q9vcc  1/1    Running   0         92s   10.42.0.8   master  ..

kubectl logs fluentd-q9vcc
# 2020-07-05 04:12:05 +0000 [info]: parsing config file is succeeded ..
# 2020-07-05 04:12:05 +0000 [info]: using configuration file: <ROOT>
#   <match fluent.**>
#     @type null
#   </match>
# </ROOT>
# 2020-07-05 04:12:05 +0000 [info]: starting fluentd-1.4.2 pid=1 ..
# 2020-07-05 04:12:05 +0000 [info]: spawn command to main: cmdline=..
# ...
```

`Pod`가 각 서버마다 하나씩(예제에서는 1개이지만 여러 서버가 있을 때에는 여러개가 생성됩니다.) 자동으로 생성됩니다. `DaemonSet` 리소스는 모든 노드에 항상 동일한 작업을 수행해야 하는 경우 사용하는 리소스입니다. `DaemonSet`를 사용하는 장점으로 클러스터에 노드를 새롭게 추가할 때마다 따로 노드에 특별한 작업을 수행하지 않더라도 신규로 편입된 노드에 자동으로 필요한 `Pod`들이 생성됩니다.그래서 로그 수집, 리소스 모니터링 등 모든 노드가 동일하게 수행하는 작업에 대해서는 `DaemonSet`을 사용하는 것이 편리합니다.


## Job & CronJob

### Job

`Job` 리소스는 `Pod`와는 다르게 항상 실행되고 있는 daemon성 프로세스가 아닌 한번 실행하고 완료가 되는 batch성 프로세스를 처리하는 용도로 만들어졌습니다.
간단한 기계학습 모델을 `Job`으로 실행 시켜 보겠습니다.

- `train.py`: 간단한 기계학습 스크립트
- `Dockerfile`: 기계학습 스크립트를 도커 이미지로 변환
- `job.yaml`: `Job` 실행을 위한 리소스 정의서

[`train.py`](train.py) 파일의 상단을 보시면 파라미터를 받는 부분이 있고 맨끝 부분에서는 모델의 성능을 출력하는 부분이 있는 것을 알 수 있습니다.

```python
# train.py

#####################
# parameters
#####################
epochs = int(sys.argv[1])
activate = sys.argv[2]
dropout = float(sys.argv[3])
print(sys.argv)
#####################

# ...
# ...

score = model.evaluate(x_test, y_test, verbose=0)
print('Test loss:', score[0])
print('Test accuracy:', score[1])

```

```Dockerfile
FROM python:3.6.8-stretch

RUN pip install tensorflow==1.5 keras==2.0.8 h5py==2.7.1

COPY train.py .

ENTRYPOINT ["python", "train.py"]
```

```bash
# 도커 이미지 빌드
docker build . -t <USERNAME>myfirstjob

# 도커 이미지 업로드
docker push <USERNAME>myfirstjob
```

```yaml
# job.yaml
apiVersion: batch/v1
kind: Job
metadata:
  name: myfirstjob
spec:
  template:
    spec:
      containers:
      - name: ml
        image: $USERNAME/myfirstjob
        args: ['5', 'softmax', '0.5']
      restartPolicy: Never
  backoffLimit: 2
```

- `template`: `Pod` 리소스의 spec과 동일합니다. `Job`도 결국은 내부적으로 `Pod`를 통해 실행되기 때문입니다.
- `backoffLimit`: restart 횟수를 지정합니다. 예시에서는 총 2번의 restart 시도 후 최종적으로 실패라고 기록이 됩니다.

```bash
# 이미지를 빌드합니다.
docker build . -t $USERNAME/myfirstjob
# 이미지를 업로드합니다.
docker push $USERNAME/myfirstjob

# vi job.yaml --> change image: $USERNAME 
kubectl apply -f job.yaml
# job.batch/myfirstjob created

kubectl get job
# NAME         COMPLETIONS   DURATION   AGE
# myfirstjob   0/1           9s         9s

kubectl get pod
# NAME                                             READY   STATUS      RESTARTS   AGE
# myfirstjob-l5thh                                 1/1     Running     0          9s

# 로그 확인
kubectl logs -f myfirstjob-l5thh 
# ['train.py', '5', 'softmax', '0.5']
# Downloading data from https://s3.amazonaws.com/img-datasets/mnist.npz
# Using TensorFlow backend.
# 11460608/11490434 [============================>.] - ETA: 0s30000 train samples
# 2000 test samples
# _________________________________________________________________
# Layer (type)                 Output Shape              Param #
# =================================================================
# dense_1 (Dense)              (None, 512)               401920
# _________________________________________________________________
# ...

# Job 완료 확인
kubectl get job,pod

kubectl delete job myfirstjob
```

몇가지 짚고 넘어가고 싶은 내용들이 있는데요.
1. 먼저 도커허브에서 레포지토리를 따로 생성하지 않았음에도 불구하고 `docker push` 실행시 정상적으로 업로드가 됩니다. 사실 Web을 통해 명시적으로 저장소를 생성하지 않아도 `docker push`를 통해 저장소가 존재하지 않으면 자동으로 만들어 줍니다. 
2. 내 로컬에 myfirstjob 이미지를 바로 사용하면 되는데 왜 굳이 원격 저장소에 저장하고 그것을 참조해서 `Job`을 실행할까요? 쿠버네티스는 여러 워커 서버들이 연결되어 있는 클러스터 기반의 플랫폼이기 때문에 기본적으로 항상 원격 저장소의 이미지를 사용하게끔 설계가 되어 있습니다.

### CronJob

`CronJob`은 `Job` 리소스와 유사하지만 time-based의 일정 주기로 `Job`을 실행할 수 있도록 확장된 리소스입니다.

```bash
cat << EOF | kubectl apply -f -
apiVersion: batch/v1beta1
kind: CronJob
metadata:
  name: hello
spec:
  schedule: "*/1 * * * *"
  jobTemplate:
    spec:
      template:
        spec:
          containers:
          - name: hello
            image: busybox
            args:
            - /bin/sh
            - -c
            - date; echo Hello from the Kubernetes cluster
          restartPolicy: OnFailure
EOF
```

`CronJob` 생성시 schedule에 등록된 주기마다 등록된 `Job`이 실행되는 것을 확인할 수 있습니다.
```bash
kubectl get cronjob
# NAME    SCHEDULE      SUSPEND   ACTIVE   LAST SCHEDULE   AGE
# hello   */1 * * * *   False     0        <none>          4s

kubectl get job
# NAME               COMPLETIONS   DURATION   AGE
# hello-1584873060   0/1           3s         3s

kubectl get pod
# NAME                     READY   STATUS      RESTARTS   AGE
# hello-1593329160-pkkkf   0/1     Completed   0          6s

kubectl logs hello-1593329160-pkkkf
# Sun Jun 28 07:26:12 UTC 2020
# Hello from the Kubernetes cluster
```


더 많은 리소스를 확인하고 싶다면 아래 명령을 통해 확인할 수 있습니다.

```bash
kubectl api-resources
```

#### Clean up

```bash
kubectl delete deploy --all
kubectl delete rs --all
kubectl delete pod --all
kubectl delete svc --all
kubectl delete job --all
kubectl delete cronjob --all
kubectl delete ds --all
```

---

## :trophy: Do it more

1. `네트워킹`에서 만든 워드프레스 앱을 `Deployment`로 변경해 봅시다. (wordpress, db 둘다)
2. wordpress `Deployment`의 `replica` 개수를 3으로 주어 가용성을 높혀 주시기 바랍니다.
3. App에서 사용된 환경변수 및 설정 파일을 전부 `ConfigMap`으로 분리하여 생성해 주시기 바랍니다.
4. 매 1분마다 워드프레스 어플리케이션을 호출하여 결과를 보여주는 `CronJob`을 생성해 주시기 바랍니다. (optional)


---


# K8s CI / CD

## Github Actions 개념

##### Workflow

소스코드를 내려받고 빌드를 하고 최종적으로 빌드 결과물을 저장하거나 배포하는 등 자동화된 전체 프로세스를 나타낸 순서도입니다. GitHub에게 나만의 동작을 정의한 workflow file를 만들어 전달하면 GitHub Actions이 그것을 보고 그대로 실행 시켜줍니다.

##### Job

잡은 여러 step을 그룹 지어주는 역할을 하며 단일한 가상 환경을 제공해 줍니다. 각 잡에 서로 다른 가상 환경을 부여할 수 있고 잡끼리의 디펜던시를 설정하거나 병렬로 실행할 수 있는 기능을 제공합니다.

##### Step

step은 Job안에서 sequential하게 실행되는 프로세스 단위이며 파일시스템을 통하여 서로 정보를 공유할 수 있습니다. step에서 명령을 내리거나 action을 실행할 수 있습니다.

##### Action

step에서는 단순히 OS에서 지원하는 명령을 내리는 것 뿐만 아니라 미리 제공된 action 혹은 사용자가 직접 customizing한 action을 호출할 수 있는 매커니즘을 제공하고 이를 action이라 부릅니다. action은 내부적으로 도커 컨테이너 혹은 javascript를 통해서 실행되며 도커를 사용할 경우 사용자는 Dockerfile을 제공함으로써 action을 커스텀화할 수 있습니다.

##### Event

정의한 workflow를 언제 실행 시킬지 알려줍니다. 기본적으로 cron잡과 같이 시간 based로 실행시킬 수도 있으며 보통 많이 사용하듯이 push, PR 등 소스코드 레포지토리의 이벤트를 기준으로 실행시킬 수 있습니다.

## `main.yml` 만들기

```yaml
# .github/
#      workflows/
#              main.yml
name: my first workflow              # workflow 이름
on: push                             # event trigger on push

jobs:
  build:                             # job id
    name: Hello world action         # job 이름
    runs-on: ubuntu-latest           # 가상 환경
    steps:
    - name: checkout source code     # step 01 이름
      uses: actions/checkout@master  # 소스코드 checkout
    - name: say hello                # step 02 이름
      run: echo "hello world"        # linux command 실행
```

```bash
git add .github/workflows/main.yml
git commit -m "my first actions workflow"
git push origin master
```
